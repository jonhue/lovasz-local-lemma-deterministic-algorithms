\documentclass{beamer}
%
% Choose how your presentation looks.
%
% For more themes, color themes and font themes, see:
% http://deic.uab.es/~iblanes/beamer_gallery/index_by_theme.html
%
\mode<presentation>
{
  \usetheme{default}      % or try Darmstadt, Madrid, Warsaw, ...
  \usecolortheme{default} % or try albatross, beaver, crane, ...
  \usefonttheme{default}  % or try serif, structurebold, ...
  \setbeamertemplate{navigation symbols}{}
  \setbeamertemplate{caption}[numbered]
  \setbeamertemplate{footline}[frame number]
  \setbeamertemplate{itemize items}[circle]
%   \setbeamertemplate{theorems}[numbered]
  \setbeamercolor*{structure}{bg=white,fg=blue}
  \setbeamerfont{block title}{size=\normalsize}
  \setbeamercolor{bibliography entry author}{fg=black}
  \setbeamercolor{bibliography entry title}{fg=black}
  \setbeamercolor{bibliography entry note}{fg=black}
}

% \newtheorem{proposition}[theorem]{Proposition}
% \theoremstyle{definition}
% \newtheorem{algorithm}[theorem]{Algorithm}
% \newtheorem{idea}[theorem]{Idea}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{nicefrac}
\usepackage{tabularx}
\usepackage{makecell}
% \usepackage{amsmath,amsfonts,amsthm,amssymb,mathrsfs,bbm,mathtools}
% \usepackage{enumitem}
\usepackage{tikz}
% \usetikzlibrary{patterns}
% \usetikzlibrary{intersections}
% \usepackage{pgfplots}
% \usepgfplotslibrary{fillbetween}
% \usepgfplotslibrary{dateplot}
% \usepackage{pgfplotstable}
\usepackage{appendixnumberbeamer}

% \usepackage{booktabs}
% \usepackage[final]{microtype}
% \usepackage{caption}
% \usepackage{amsmath}
% \usepackage{mathtools}
% \usepackage{amsthm,thmtools}
% % \usepackage[nottoc]{tocbibind}
% % \usepackage[ruled]{algorithm2e}
% \usepackage{enumerate}
% \usepackage[italic]{esdiff}
% \usepackage{subcaption}
% \usepackage{ltablex}
% \usepackage{multirow}

\usepackage{pifont}
\newcommand{\cmark}{\text{\ding{51}}}
\newcommand{\xmark}{\text{\ding{55}}}

%--------Pseudocode--------
\usepackage{xcolor,amsmath}
\usepackage{algorithm2e}
\DontPrintSemicolon
% \SetAlgoSkip{bigskip}

% % Define pseudocode formatting
% \renewcommand{\KwSty}[1]{\textnormal{\textcolor{blue!90!black}{\ttfamily\bfseries #1}}\unskip}
% \renewcommand{\ArgSty}[1]{\textnormal{\ttfamily #1}\unskip}
% \SetKwComment{Comment}{\color{green!50!black}// }{}
% \renewcommand{\CommentSty}[1]{\textnormal{\ttfamily\color{green!50!black}#1}\unskip}
% \newcommand{\assign}{\leftarrow}
% % \newcommand{\var}{\texttt}
% \newcommand{\FuncCall}[2]{\texttt{\bfseries #1(#2)}}
% \SetKwProg{Function}{function}{}{}
% \renewcommand{\ProgSty}[1]{\texttt{\bfseries #1}}

% % Settings for pgfplots
% \pgfplotsset{compat=newest}

% \renewcommand\tabularxcolumn[1]{m{#1}}
% \newcolumntype{R}{>{\raggedleft\arraybackslash}X}=

% \def\code#1{\texttt{\frenchspacing#1}}
\def\padding{\vspace{0.5cm}}
\def\spadding{\vspace{0.25cm}}
\def\b{\textcolor{blue}}
\def\r{\textcolor{red}}
\def\o{\textcolor{orange}}
\def\g#1{{\usebeamercolor[fg]{block title example}{#1}}}
\definecolor{softgreen}{RGB}{124,216,23}

% fix for \pause in align
\makeatletter
\let\save@measuring@true\measuring@true
\def\measuring@true{%
  \save@measuring@true
  \def\beamer@sortzero##1{\beamer@ifnextcharospec{\beamer@sortzeroread{##1}}{}}%
  \def\beamer@sortzeroread##1<##2>{}%
  \def\beamer@finalnospec{}%
}
\makeatother

% \DeclarePairedDelimiter{\norm}{\lVert}{\rVert}
\NewDocumentCommand{\follows}{}{\ensuremath{\rightsquigarrow}\hspace{0.5em}}
\newcommand*{\defeq}{\overset{.}{=}}
\newcommand*{\eqdef}{\overset{.}{=}}
\RenewDocumentCommand{\Pr}{om}{Pr\IfValueT{#1}{_{#1}}{}[#2]}
\NewDocumentCommand{\E}{om}{\mathbb{E}\IfValueT{#1}{_{#1}}{}#2}
\RenewDocumentCommand{\O}{m}{\mathcal{O}(#1)}
\NewDocumentCommand{\B}{}{\mathcal{B}}
\NewDocumentCommand{\G}{}{\mathcal{G}}
\NewDocumentCommand{\C}{}{\o{\mathcal{C}}}
\RenewDocumentCommand{\L}{}{\r{\ensuremath{\mathcal{L}_\tau}}}
\NewDocumentCommand{\U}{}{\b{\ensuremath{\mathcal{U}_\tau}}}
\NewDocumentCommand{\pmax}{}{p_\mathrm{max}}
\NewDocumentCommand{\taumax}{}{\ensuremath{\tau_\mathrm{max}}}
\NewDocumentCommand{\var}{m}{\mathrm{var}(#1)}
\NewDocumentCommand{\maxsize}{m}{\mathrm{maxsize}(#1)}
\NewDocumentCommand{\poly}{m}{\mathrm{poly}(#1)}
\NewDocumentCommand{\polylog}{m}{\mathrm{polylog}(#1)}
\NewDocumentCommand{\distr}{}{D}
\NewDocumentCommand{\law}{}{p}
\NewDocumentCommand{\epslaw}{}{\ensuremath{\law^{1-\epsilon}}}
\NewDocumentCommand{\w}{}{\ensuremath{w_\law}}
\NewDocumentCommand{\epsw}{}{\ensuremath{w_{\epslaw}}}
\NewDocumentCommand{\epsalpha}{}{\ensuremath{\alpha_{\law^{1-\epsilon}}}}
\NewDocumentCommand{\epsW}{}{\ensuremath{W_\epsilon}}
\NewDocumentCommand{\compat}{mm}{#1[#2]}

\usepackage[sorting=ynt,style=alphabetic]{biblatex}
\addbibresource{sources.bib}

\renewcommand{\footnotesize}{\tiny}

\begin{document}

\title[Deterministic Algorithms for the Lovász Local Lemma]{Deterministic Algorithms \\ for the Lovász Local Lemma\footfullcite{harris2022deterministic}}
\author{Jonas Hübotter and Duri Janett \\ Advised by Yassir Akram}
\date{March 29, 2022}

\begin{frame}
  \titlepage
\end{frame}

% \begin{frame}{Outline}
%  \tableofcontents[subsubsectionstyle=hide,pausesections]
% \end{frame}
% \AtBeginSection[]
%   {
%      \begin{frame}[allowframebreaks]{Plan}
%      \tableofcontents[currentsection, sectionstyle=show/hide, hideothersubsections]
%      \end{frame}
%   }

\section{Introduction}
\subsection{Lovász Local Lemma and the MT Algorithm}
\begin{frame}{Setting}
Distribution $\distr$ over independent $\Sigma$-valued coordinates $X_1, \dots, X_n$.
``Bad-events'' $\B = \{B_1, \dots, B_m\}$, each a boolean function of some subset of coordinates $\var{B_i} \subseteq \{X_1,\dots,X_n\}$ with law $\law$.

\begin{example}[3-SAT]
\begin{columns}
\begin{column}{.3\textwidth}
$\begin{aligned}
B_1 &\defeq f_1(X_1,X_3,X_5) \\
B_2 &\defeq f_2(X_2,X_3,X_6) \\
B_3 &\defeq f_3(X_1,X_5,X_6) \\
B_4 &\defeq f_4(X_2,X_4,X_7)
\end{aligned}$
\end{column}
\begin{column}{.3\textwidth}
\input{figures/3sat}
\end{column}
\end{columns}
\end{example}\pause

\begin{theorem}[(Symmetric) Lovász Local Lemma]
If for any $i$, $\law(B_i) \leq \pmax$ and $B_i$ affects at most $d$ bad-events, then $e \pmax d \leq 1$ implies $\Pr{\text{all $B_i$ avoided}} > 0$.
\end{theorem}\pause\spadding

For \g{$k$-SAT}, $\law \equiv 2^{-k}$ \follows satisfiable if any literal appears in $d \leq \nicefrac{2^k}{e}$ clauses!\pause\ How to find a satisfying assignment?
\end{frame}

\begin{frame}{Applications}
\begin{example}[k-Coloring]
Choose $c(v) \sim \text{Unif}([k])$ independently.\pause\par
$B_{i,v} \defeq c(v) = i$ and $v$ has neighbor with color $i$.\par
$B_{i,v}$ affects $B_{i',v'}$ iff $v$ and $v'$ have distance $\leq 2$\pause\ \follows $d \leq k \Delta^2$.\pause\par
$p(B_{i,v}) = \frac{1}{k}(\sum_{u \in N(v)} \frac{1}{k}) \leq \frac{\Delta}{k^2}$\pause\ \follows if $e \Delta^3 \leq k$, has $k$-coloring!
\end{example}\pause\padding

More applications:
\begin{enumerate}
    % \item Satisfiability
    \item Defective colouring 
    \item Hypergraph colouring
    \item Strong colouring
    \item Finding directed cycles of certain length (see exam, task 2 :))
    \item Independent transversals
\end{enumerate}\pause

\follows algorithmic versions of the Lovász Local Lemma yield automatic algorithms for these problems!
\end{frame}

\begin{frame}{Prior Work}
\begin{algorithm}[H]
    \TitleOfAlgo{MT-Algorithm}
    Draw $X$ from distribution $\distr$\;
    \While{some bad-event is true on $X$}{
        Select any true bad-event $B$\;
        For each $i \in \var{B}$, draw $X_i$ from its distribution in $\distr$\;
    }
\end{algorithm}\pause
\follows converges within expected polynomial time.\footfullcite{moser2010constructive}
\end{frame}

\subsection{Prior Work}
\begin{frame}{Prior Work}
\small
\begin{center}
\begin{tabular}{c|l|l|l}
 Paper & Criterion & Det.? & Parallel? \\[0.1em]\hline
 \footfullcite{moser2010constructive}\rule{0pt}{2.6ex} & asymmetric LLL & \xmark & (\cmark) \\
 \footnotemark[\value{footnote}] & asymmetric LLL and $d \leq \O{1}$ & \cmark & (\cmark) \\
 \footfullcite{chandrasekaran2013deterministic} & symmetric LLL with $\epsilon$-exponential slack & \cmark & (\cmark) \\
 \footfullcite{haeupler2017parallel} & Shearer criterion with $\epsilon$-slack & \xmark & \cmark \\ % parallel: $\O{\log^2 n}$
 \footnotemark[\value{footnote}] & \makecell[lt]{symmetric LLL with $\epsilon$-exponential slack \\ and atomic bad-events} & \cmark & \cmark \\ % parallel: $\O{\log^2 n}$
 \footfullcite{harris2018deterministic} & \makecell[lt]{symmetric LLL and bad-events \\ depend on $\polylog{n}$ variables} & \cmark & \cmark \\ % parallel: $\O{\log n}$
\end{tabular}\spadding

(\cmark) : under more complex conditions
\end{center}
\end{frame}

\subsection{Overview of Results}
\begin{frame}{Contributions}
\begin{enumerate}
    \item \emph{Deterministic algorithm} with a simpler \& more general condition that is satisfied by \emph{most} variants of the LLL.\pause
    \item Faster \emph{parallel algorithm} with simpler conditions.\pause
    \item Algorithm that finds a configuration avoiding bad events such that the (weighted) probability of some auxiliary events is not much more than their expectation.
\end{enumerate}
\end{frame}

\section{Background}
\begin{frame}{Plan}
\tableofcontents[currentsection, sectionstyle=show/shaded, hideothersubsections]
\end{frame}

\subsection{Alternative Characterization of MT Algorithm}
\begin{frame}{Alternative Characterization of MT Algorithm}
Consider the \b{resampling table} $R$ drawn according to distribution $\distr$:\spadding

\begin{columns}
\begin{column}{.25\textwidth}
\input{figures/resampling_table}\vspace{0.15em}\pause
\end{column}\pause
\begin{column}{.1\textwidth}
\centering $\overset{\text{resampling $X_1$}}{\follows}$
\end{column}
\begin{column}{.3\textwidth}
\input{figures/shifted_resampling_table}
\end{column}
\begin{column}{.05\textwidth}
\end{column}
\end{columns}\pause

When resampling $B_i$, shift rows $\var{B_i}$ to left.\pause\padding

\follows MT algorithm deterministic with respect to resampling table!
\end{frame}

% \subsection{Outline}
% \begin{frame}{Outline}
%     Goal: Find a resampling table such that after poly. resamples all bad-events are avoided.\spadding
    
%     Idea: Choose $R$ such that the MT algorithm only performs resamples that the randomized variant is likely to perform.\pause\padding
    
%     \begin{enumerate}
%         \item Construct set of unlikely resamples of randomized MT algorithm.\pause
%         \item Use method of conditional expectations to find a resampling table $R$ such that all of these resamplings are avoided.\pause
%         \item Simulate MT algorithm using $R$.
%     \end{enumerate}
% \end{frame}

\subsection{Counting Resamples}
\begin{frame}{Counting Resamples}
Find an injective mapping from resamples to some ``countable'' structure.\pause

\begin{block}{Why may executions be long?}
Given a resampling table $R$, a \b{(partial) execution} of the MT algorithm is described by the sequence of resampled bad-events.\pause\spadding

\begin{columns}
\begin{column}{.15\textwidth}
\centering $B_1, B_2, B_3\onslide<5->{, \r{B_4}}$
\end{column}
\begin{column}{.0\textwidth}
\centering $\mapsto$
\end{column}\pause
\begin{column}{.2\textwidth}
\centering\input{figures/witness_dag}
\end{column}
\begin{column}{.3\textwidth}
\b{Witness DAG} $\hat{G}$

$B_i \longrightarrow B_j$ iff $i < j$\par and $B_i$ affects $B_j$
\end{column}
\end{columns}\pause\pause

\follows $\hat{G}$ is always a DAG!\pause\ But why use DAGs?
\end{block}
\end{frame}

\begin{frame}{Counting Resamples}
We can reconstruct the final configuration of the MT algorithm!\spadding

\begin{columns}[T]
\begin{column}{.4\textwidth}
\centering\vspace{-1em}\input{figures/witness_dag_final}\vspace{-1.5em}\spadding

{\small
\vspace{-2em}\begin{align*}
\var{B_1} = \{X_1,X_3,X_5\} \\
\var{B_2} = \{X_2,X_3,X_6\} \\
\var{B_3} = \{X_1,X_5,X_6\} \\
\var{B_4} = \{X_2,X_4,X_7\}
\end{align*}
}
\end{column}\pause
\begin{column}{.4\textwidth}
\centering\input{figures/resampling_table_wdag}\spadding

\onslide<2->{fixed resampling table $R$}
\onslide<3->{resamples: \b{$B_1$}}\onslide<4->{, \textcolor{softgreen}{$B_2$}}\only<5-7>{, \textcolor{orange}{$B_3$}}\onslide<6,9->{, \r{$B_4$}}\onslide<10->{, \textcolor{orange}{$B_3$}}
\end{column}
\begin{column}{.1\textwidth}
\end{column}
\end{columns}\spadding

\onslide<11->{\follows may encode multiple executions, but \emph{all} lead to the same final configuration!}

\onslide<12->{\follows bad-events depend on \emph{disjoint} entries of $R$!}

\onslide<13->{\follows configuration at step $t$ is drawn according to $\distr$!}
\end{frame}

% \begin{frame}{Counting Resamples}
% \begin{block}{Witness DAG of resamples}
% \begin{center}
% \input{figures/witness_dag_subgraph}
% \end{center}

% Observe: Given a resampling table $R$, $\hat{G}(B_t)$ explains the values of $\var{B_t}$ before \& after resampling $B_t$.\pause\spadding

% \follows we have an injective mapping!
% \end{block}
% \end{frame}

\begin{frame}{Counting Resamples}
Do we map resamples to \emph{all} witness DAGs?\pause\par
No! \follows we can improve our counting!\pause\spadding

\begin{itemize}
    \item $\hat{G}(B_i)$ always has a single sink (set denoted $\G$)\pause
    \item Given resampling table $R$, do all single-sink witness DAGs $G$ correspond to a possible resample?\pause
    
    \follows No! \pause$G$ \& $R$ must be \b{compatible} (set denoted $\compat{\G}{R}$)\pause\spadding
    
    \underline{Note}: $\Pr[R \sim \distr]{\text{$G$ \& $R$ compatible}} \pause= \prod_{B \in G} \law(B) \pause\eqdef \w(G)$.
\end{itemize}\pause\spadding

\follows for fixed resampling table $R$, at most $|\compat{\G}{R}|$ resamplings\pause

\vspace{-1.5em}\begin{align*}
    \E{|\compat{\G}{R}|} \pause= \sum_{G \in \G} \Pr{\text{$G$ \& $R$ compatible}} = \sum_{G\in\G} \w(G) \pause\eqdef \underbrace{\w(\G) \pause < \infty}_{\text{\b{Shearer Criterion}}}.
\end{align*}
\end{frame}

\section{A Deterministic Algorithm}
\begin{frame}{Plan}
\tableofcontents[currentsection, sectionstyle=show/shaded, hideothersubsections]
\end{frame}

\subsection{Likely \& Unlikely Resamples}
\begin{frame}{Likely \& Unlikely Resamples}
Want to find resampling table $R$ such that $|\compat{\G}{R}|$ is polynomial.\pause\par
Idea: choose $R$ such that unlikely resamples are avoided!

\begin{columns}[T]
\begin{column}{.55\textwidth}
\g{Example}\quad $\w(G) = \only<2-3>{\nicefrac{1}{4}}\only<4>{\nicefrac{1}{16}}\only<5->{\nicefrac{1}{32}}$.\vspace{0.3em}

\onslide<6->{For a threshold $\tau \in [0,1]$, \begin{itemize}
    \item let $\L \subseteq \only<-8>{\G}\only<9->{\C}$ be the set of \b{likely} witness DAGs, $\w(G) \geq \tau$\only<7->{;
    \item let $\U \subseteq \only<-8>{\G}\only<9->{\C}$ be the set of \b{(most likely) unlikely} witness DAGs, $\w(G) < \tau$ such that all strict prefixes are likely.}
\end{itemize}}

\onslide<8->{\underline{Problem}: $\U$ does not form a complete boundary of $\L$!}
\end{column}
\begin{column}{.36\textwidth}
\centering\input{figures/likely_unlikely_wdags}
\flushright\small $G$, suppose $\law \equiv \nicefrac{1}{2}$.
\end{column}
\end{columns}\vspace{0.25em}\pause\pause\pause\pause\pause\pause\pause

Consider the larger set $\C$ of all witness DAGs attainable by removing the sink of some single-sink witness DAG\pause\ \follows $\G \subseteq \C$.\pause\spadding

\follows fixing resampling table $R$, if $\compat{\U}{R} = \emptyset$, then $\compat{\C}{R} \subseteq \compat{\L}{R}$.
\end{frame}

\begin{frame}{Finding Resampling Table avoiding $\U$}
Using the method of conditional expectation, we find $R$ such that \vspace{-0.5em}\begin{align*}
    |\compat{\U}{R}| \leq \E[R \sim \distr]{|\compat{\U}{R}|} \pause = \w(\U).
\end{align*}\pause

\vspace{-1.8em}\follows if we choose $\tau$ such that $\w(\U) < 1$,\par then $\compat{\U}{R} = \emptyset$ and $\compat{\G}{R} \subseteq \compat{\L}{R}$.\pause\padding

What is the effect of changing $\tau$?\pause\vspace{0.1em}

\centering\input{figures/threshold}
\end{frame}

\begin{frame}{Choosing the Threshold}
Can we choose $\tau$ such that $\w(\U) < 1$ and $\U$ and $\L$ are of polynomial size?\pause

\begin{enumerate}
    \item What is the largest $\tau$ guaranteeing $\w(\U) < 1$?\pause\spadding
    
    We compare $\w$ and $\epsw$.\pause\par
    For $G \in \U$, suppose $\epsw(G) < \tau$.\pause\par
    Then, $\w(G) < \tau^\epsilon \epsw(G)$\pause\ \follows $\w(\U) < \tau^\epsilon \epsw(\U)$.\pause\par
    \follows for $\tau \leq \taumax$, we have $\w(\U) < 1$.\pause

    % % wiggle proportional to weight of object (if weight of object depends on \tau, wiggle depends on \tau)    
    % \input{figures/wiggle}\pause\vspace{-1em}
    
    % For $G \in \U$, by how much does $\w(G)$ change\par (depending on $\tau$) when perturbing $p$?\pause\par
    % We compare $\w$ and $\epsw$\pause\ \follows $\w(\U) < \tau^\epsilon \epsw(\U)$\pause\ if we choose $\U$ and $\L$ based on $\epsw$ rather than $\w$.\pause\spadding
    
    % Need to ensure that the effect of perturbing $p$ is small enough!\pause\par
    % \follows for $\tau \leq \taumax$, we have $\w(\U) < 1$.\pause
    % \follows for $\tau^\epsilon \leq \epsw(\U)^{-1}$, we have $\w(\U) < 1$\pause\ \follows $\taumax$.\pause
    
    % For $G \in \U$, we know $\w(G) < \tau$.\pause\par
    % \underline{Note}: For $\epsilon > 0$, $\w(G) = \epsw(G)^{\nicefrac{1}{(1-\epsilon)}} \pause< \tau^\epsilon \epsw(G)$\par if we choose $\U$ and $\L$ based on $\epsw$ rather than $\w$\par (this we do from now on!).\pause\par
    % \follows $\w(\U) < \tau^\epsilon \epsw(\U)$.\pause\par
    % \follows for $\tau \leq \epsw(\U)^{-\nicefrac{1}{\epsilon}} \eqdef \taumax$, we have $\w(\U) < 1$.\pause
    
    \vspace{0.3em}\begin{columns}[T]
    \begin{column}{0.4\textwidth}
    How do we compute $\tau$?\pause\par
    Use exponential backoff!
    
    \g{Example}\quad $\tau = \only<9>{2^0 = 1}\only<10>{2^{-1} = \nicefrac{1}{2}}\only<11>{2^{-2} = \nicefrac{1}{4}}\only<12->{2^{-3} = \nicefrac{1}{8}}$.\spadding%\vspace{0.25em}
    
    % \onslide<13->{\follows $\tau \geq \frac{1}{2} \taumax$}\spadding
    
    \onslide<13->{Are $\U$ and $\L$ of polynomial size?}
    \end{column}
    \begin{column}{0.12\textwidth}
    \centering\input{figures/exp_backoff}
    \end{column}
    \begin{column}{0\textwidth}
    \end{column}
    \end{columns}
\end{enumerate}
\end{frame}

\begin{frame}{Choosing the Threshold}
\begin{enumerate}
    \setcounter{enumi}{1}
    \item Is $\U \cup \L$ of polynomial size?\pause\vspace{0.25em}
    
    Bounding \# of multi-sink witness DAGs is easy!\pause\par
    What about the \# of single-sink witness DAGs?\pause
    
    \vspace{0.25em}\begin{columns}[T]
    \begin{column}{0.42\textwidth}
    \underline{Observe}: Removing the sink $B$ from $G \in \U \cup \L$,\par we have $\epsw(G - B) \geq \tau$.\spadding
    
    \onslide<5->{But $G - B$ is not necessarily single-sink! Its \o{sinks} are an independent set adjacent to $B$ in $G$.}
    \end{column}
    \begin{column}{0.1\textwidth}
    \centering\vspace{-1.5em}\input{figures/likely_unlikely_wdags_removing_sink}
    \end{column}
    \begin{column}{0\textwidth}
    \end{column}
    \end{columns}\pause\pause
    
    \follows the cumulative weight of all witness DAGs attained by deleting sink $B$ of $G \in \G$\pause\ is $\nicefrac{\epsw(\G_B)}{\epslaw(B)}$.\pause\par
    \follows $|\U \cup \L|$ is polynomial if $\nicefrac{\epsw(\G_B)}{\epslaw(B)}$ is polynomial!
    
    % \begin{align*}
    %     \sum_{B \in \B} \sum_{\substack{G \in \U \cup \L \\ \text{with sink $B$}}} \only<7>{1}\pause\frac{\epsw(G - B)}{\tau} \pause\leq \frac{1}{\tau} \sum_{B \in \B} \frac{\epsw(\G_B)}{\epslaw(B)}
    %                 %  &\pause\eqdef \frac{\epsW}{\tau} \pause\leq \frac{2 \epsW}{\taumax} = 2 \epsW \epsw(\U)^{\nicefrac{1}{\epsilon}} \pause\leq 2 \epsW^{1+\nicefrac{1}{\epsilon}}.% \text{ as $\epsw(\U) \leq \epsW$}.
    % \end{align*}
\end{enumerate}
\end{frame}

\subsection{The Algorithm}
\begin{frame}{The Algorithm}
% \r{TODO: $\epsalpha(B)$ for k-SAT}\pause

\begin{algorithm}[H]
\TitleOfAlgo{Deterministic MT-Algorithm}\pause
Using exponential backoff, select ``large'' $\tau$ such that $\w(\U) < 1$\;\pause
% Generate the witness DAGs $\U$\;\pause
Using method of conditional expectations, find resampling table $R$ avoiding $\U$\;\pause
Run the deterministic MT algorithm on $R$\;
\end{algorithm}\pause\spadding

We have seen that the final step takes at most $|\compat{\G}{R}| \leq |\compat{\L}{R}|$ iterations!
\end{frame}

\subsection{Limitations}
\begin{frame}{Limitations}
This algorithm does not cover some scenarios:
\begin{itemize}
    \item superpolynomial $|\B|$ and $|\Sigma|$
    \item non-variable probability spaces
    \item does not cover lopsidependency
\end{itemize}
\end{frame}

% \subsection{Counting Resamples with Witness DAGs}
% \subsubsection{What are Witness DAGs?}
% \begin{frame}{Frame Title}
    
% \end{frame}
% \subsubsection{From Witness DAGs to the Resampling Table to the MT Algorithm}
% \begin{frame}{Frame Title}
    
% \end{frame}
% \subsection{Shearer's Criterion}
% \begin{frame}{Frame Title}
    
% \end{frame}

% \section{A Deterministic Algorithm}
% \begin{frame}{Plan}
% \tableofcontents[currentsection, sectionstyle=show/shaded, hideothersubsections]
% \end{frame}
% \subsection{Shearer's Criterion with Slack}
% \begin{frame}{Frame Title}
    
% \end{frame}
% \subsection{Counting Witness DAGs}
% \begin{frame}{Frame Title}
    
% \end{frame}
% \subsection{Analyzing the Deterministic Algorithm}
% \begin{frame}{Frame Title}
    
% \end{frame}
% \subsection{Pre-processing the Witness DAG and Crisper Results}
% \begin{frame}{Frame Title}
    
% \end{frame}

% \section{Outlook: A Parallel Algorithm and the MT-distribution}
% \begin{frame}{Plan}
% \tableofcontents[currentsection, sectionstyle=show/shaded, hideothersubsections]
% \end{frame}
% \begin{frame}{Frame Title}
    
% \end{frame}

\begin{frame}{}
    \centering \large
    Thanks for your attention!
    Questions?
\end{frame}

\appendix

\begin{frame}{Computing the Resampling Table}
Can $R$ be computed efficiently?\pause\spadding

\underline{Observe}: The MT algorithm uses at most as many columns as the size of the largest witness DAG in $\L$\pause, which is at most $|\L|$.\pause\spadding

For each cell of $R$, choose one of $|\Sigma|$ values to minimize the conditional probability of $G$ \& $R$ being compatible for each $G \in \U$.\pause\spadding

\follows $\O{n |\L| \cdot |\Sigma| \cdot |\L| T \cdot |\U|}$\pause, where $T$ is the runtime of computing conditional probabilities of bad-events given a partial resampling table.\pause\par
Also need to generate $\U$, which can be done in $\poly{|\U|}$ time.
\end{frame}

\end{document}